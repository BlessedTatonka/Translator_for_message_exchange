{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import regex\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import requests\n",
    "\n",
    "# !pip install python_telegram_bot\n",
    "\n",
    "import logging\n",
    "import soundfile as sf\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, ReplyKeyboardRemove, Update\n",
    "from telegram.ext import (\n",
    "    Updater,\n",
    "    CommandHandler,\n",
    "    MessageHandler,\n",
    "    Filters,\n",
    "    ConversationHandler,\n",
    "    CallbackContext,\n",
    "    CallbackQueryHandler\n",
    ")\n",
    "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import codecs\n",
    "import unidecode\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, Conversation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")\n",
    "# model.to(torch.device(1))\n",
    "# conversational_pipeline = pipeline(\"conversational\", model=model, tokenizer=tokenizer, device=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:0aasd\n",
      "DialoGPT: Aasd is the best.\n",
      ">> User:1vbqwrqw\n",
      "DialoGPT: vbqwrqw is the best\n",
      ">> User:2Привет\n",
      "DialoGPT: vbqwrqw is the best\n",
      ">> User:3You think so?\n",
      "DialoGPT: I think so.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bff76fec91fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnew_user_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\">> User:{step}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbot_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchat_history_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_user_input_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnew_user_input_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchat_history_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbot_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DialoGPT: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_history_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbot_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in range(5):\n",
    "    new_user_input_ids = tokenizer.encode(input(f\">> User:{step}\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=100000, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(torch.device('cpu'))\n",
    "conversational_pipeline = pipeline(\"conversational\", model=model, tokenizer=tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, how are you?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conversation('Hi dear')\n",
    "conversational_pipeline(conv)\n",
    "conv.generated_responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/boris/F/token.txt') as token_file:\n",
    "    bot_token = token_file.readline().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 13:00:23,700 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2022-01-30 13:00:30,156 - __main__ - INFO - Bio of Boris: Привет\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message Привет\n",
      "En translated Hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 13:00:31,169 - telegram.ext.dispatcher - ERROR - No error handlers are registered, logging exception.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boris/anaconda3/lib/python3.7/site-packages/telegram/ext/dispatcher.py\", line 555, in process_update\n",
      "    handler.handle_update(update, self, check, context)\n",
      "  File \"/home/boris/anaconda3/lib/python3.7/site-packages/telegram/ext/conversationhandler.py\", line 626, in handle_update\n",
      "    new_state = handler.handle_update(update, dispatcher, check_result, context)\n",
      "  File \"/home/boris/anaconda3/lib/python3.7/site-packages/telegram/ext/handler.py\", line 198, in handle_update\n",
      "    return self.callback(update, context)\n",
      "  File \"<ipython-input-12-62fdbbe9575b>\", line 165, in extra\n",
      "    audio = synthesize(normalized, 'ru')\n",
      "  File \"<ipython-input-12-62fdbbe9575b>\", line 137, in synthesize\n",
      "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{text}?src_lang={src_lang}')\n",
      "NameError: name 'src_lang' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ru translated Хия\n",
      "khiia\n"
     ]
    }
   ],
   "source": [
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "TRANSLATE_EN_RU, TRANSLATE_RU_EN, SYNTHESIZE_EN, SYNTHESIZE_RU, EXTRA = range(5)\n",
    "\n",
    "def normalize_str(txt) -> str:\n",
    "    # TODO: REPLACE WITH YOUR OWN NORMALIZATION LOGIC HERE!!!!   \n",
    "    valid_chars = (\" \", \"'\", \"!\", \".\", \"?\", \"&\",\n",
    "                   \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "                   \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\",\n",
    "                   \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "                   \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\",\n",
    "                  )\n",
    "    new_txt = unidecode.unidecode(txt.lower().strip())\n",
    "    res_arr = []\n",
    "    for c in new_txt:\n",
    "        if c in valid_chars:\n",
    "            res_arr.append(c)\n",
    "        else:\n",
    "            res_arr.append(' ')\n",
    "    res = ''.join(res_arr).strip()    \n",
    "    return ' '.join(res.split())\n",
    "\n",
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    return menu(update, context)\n",
    "\n",
    "\n",
    "def menu(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Sends a message with three inline buttons attached.\"\"\"\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Translate en->ru\", callback_data='Translate en->ru'),\n",
    "            InlineKeyboardButton(\"Translate ru->en\", callback_data='Translate ru->en'),\n",
    "        ],\n",
    "        [\n",
    "            InlineKeyboardButton(\"Synthesize en\", callback_data='Synthesize en'),\n",
    "            InlineKeyboardButton(\"Synthesize ru\", callback_data='Synthesize ru')\n",
    "        ],\n",
    "        [InlineKeyboardButton(\"EXTRA\", callback_data='EXTRA')], ## REMOVE LATER\n",
    "        [InlineKeyboardButton(\"cancel\", callback_data='cancel')],\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "\n",
    "    update.message.reply_text('Please choose:', reply_markup=reply_markup)\n",
    "\n",
    "    return ConversationHandler.END\n",
    "\n",
    "def button(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Parses the CallbackQuery and updates the message text.\"\"\"\n",
    "    query = update.callback_query\n",
    "\n",
    "    # CallbackQueries need to be answered, even if no notification to the user is needed\n",
    "    # Some clients may have trouble otherwise. See https://core.telegram.org/bots/api#callbackquery\n",
    "    query.answer()\n",
    "\n",
    "    query.edit_message_text(text=f\"Selected option: {query.data}\")\n",
    "\n",
    "    if query.data == \"Translate en->ru\":\n",
    "        return TRANSLATE_EN_RU\n",
    "    elif query.data == \"Translate ru->en\":\n",
    "        return TRANSLATE_RU_EN\n",
    "    elif query.data == \"Synthesize en\":\n",
    "        return SYNTHESIZE_EN\n",
    "    elif query.data == \"Synthesize ru\":\n",
    "        return SYNTHESIZE_RU\n",
    "    elif query.data == \"cancel\":\n",
    "        return ConversationHandler.END\n",
    "    elif query.data == \"EXTRA\":\n",
    "        return EXTRA\n",
    "\n",
    "\n",
    "def help_command(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Displays info on how to use the bot.\"\"\"\n",
    "    update.message.reply_text(\"Use /start to test this bot.\")\n",
    "\n",
    "    \n",
    "def get_message(update: Update) -> str:\n",
    "    message = update.message.text\n",
    "    \n",
    "    message = message.replace('?', '&quest')\n",
    "    \n",
    "    return message\n",
    "    \n",
    "def translate_en_ru(update: Update, context: CallbackContext) -> None:\n",
    "    translate(update, context, 'en', 'ru')                \n",
    "    \n",
    "def translate_ru_en(update: Update, context: CallbackContext) -> None:\n",
    "    translate(update, context, 'ru', 'en')\n",
    "    \n",
    "def translate(update: Update, context: CallbackContext, src_lang, trg_lang) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = get_message(update)\n",
    "    request = requests.get(f'http://127.0.0.1:8000/translate/{message}?src_lang={src_lang}&trg_lang={trg_lang}')\n",
    "    \n",
    "    translation = request.json()['translation']\n",
    "    \n",
    "    update.message.reply_text(translation[0]) \n",
    "    \n",
    "def translate(text, src_lang, trg_lang) -> str:\n",
    "    request = requests.get(f'http://127.0.0.1:8000/translate/{text}?src_lang={src_lang}&trg_lang={trg_lang}')\n",
    "    translation = request.json()['translation']\n",
    "    return translation[0]\n",
    "    \n",
    "    \n",
    "def synthesize_en(update: Update, context: CallbackContext) -> None:\n",
    "    synthesize(update, context, 'en')\n",
    "    \n",
    "def synthesize_ru(update: Update, context: CallbackContext) -> None:\n",
    "    synthesize(update, context, 'ru')\n",
    "    \n",
    "def synthesize(update: Update, context: CallbackContext, src_lang) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = get_message(update)\n",
    "    message = normalize_str(message)\n",
    "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{message}?src_lang={src_lang}')\n",
    "    \n",
    "    audio = request.json()['audio']\n",
    "    \n",
    "    audio_name = 'audio/' + message[:12] + '.wav'\n",
    "    \n",
    "    sf.write(audio_name, audio, 22050)\n",
    "    \n",
    "    context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "\n",
    "def synthesize(text, src_lang)\n",
    "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{text}?src_lang={src_lang}')\n",
    "    \n",
    "    audio = request.json()['audio']\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=22050)\n",
    "    \n",
    "    return reduced_noise\n",
    "    \n",
    "def extra(update: Update, context: CallbackContext) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = update.message.text\n",
    "    print('Original message', message)\n",
    "    message = translate(message.replace('?', '&quest'), 'ru', 'en')\n",
    "    print('En translated', message)\n",
    "    \n",
    "    conv = Conversation(message)\n",
    "    conversational_pipeline(conv)\n",
    "    response = conv.generated_responses[0]\n",
    "    \n",
    "    message = translate(response.replace('?', '&quest'), 'en', 'ru')\n",
    "    print('Ru translated', message)\n",
    "    normalized = normalize_str(message)\n",
    "    print(normalized)            \n",
    "                               \n",
    "    if normalized == '':\n",
    "        normalized = '.'\n",
    "    \n",
    "    audio = synthesize(normalized, 'ru')\n",
    "    audio_name = 'audio/' + response + '.wav'\n",
    "    sf.write(audio_name, reduced_noise, 22050)\n",
    "    \n",
    "    context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "    \n",
    "# def extra(update: Update, context: CallbackContext) -> None:\n",
    "#     user = update.message.from_user\n",
    "#     logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "#     message = update.message.text\n",
    "    \n",
    "#     conv = Conversation(message)\n",
    "#     conversational_pipeline(conv)\n",
    "#     response = conv.generated_responses[0]\n",
    "#     normalized_response = normalize_str(response.replace('?', '&quest'))\n",
    "    \n",
    "#     if normalized_response == '':\n",
    "#         normalized_response = '.'\n",
    "    \n",
    "#     request = requests.get(f'http://127.0.0.1:8000/synthesize/{normalized_response}?src_lang=ru')\n",
    "    \n",
    "    \n",
    "#     audio = request.json()['audio']\n",
    "#     reduced_noise = nr.reduce_noise(y=audio, sr=22050)\n",
    "#     audio_name = 'audio/' + response + '.wav'\n",
    "#     sf.write(audio_name, reduced_noise, 22050)\n",
    "    \n",
    "#     context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "    \n",
    "    \n",
    "def cancel(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Cancels and ends the conversation.\"\"\"\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"User %s canceled the conversation.\", user.first_name)\n",
    "#     update.message.reply_text(\n",
    "#         'Пока.', reply_markup=ReplyKeyboardRemove()\n",
    "#     )\n",
    "\n",
    "    return menu(update, context)\n",
    "\n",
    "    \n",
    "def main() -> None:\n",
    "    \"\"\"Run the bot.\"\"\"\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    updater = Updater(bot_token)\n",
    "\n",
    "    updater.dispatcher.add_handler(CommandHandler('start', start))\n",
    "#     updater.dispatcher.add_handler(CommandHandler('menu', menu))\n",
    "#     updater.dispatcher.add_handler(CallbackQueryHandler(button))\n",
    "    updater.dispatcher.add_handler(CommandHandler('help', help_command))\n",
    "    updater.dispatcher.add_handler(ConversationHandler(\n",
    "        entry_points=[CallbackQueryHandler(button)],\n",
    "        states={\n",
    "            TRANSLATE_EN_RU: [MessageHandler(Filters.text & ~Filters.command, translate_en_ru)],\n",
    "            TRANSLATE_RU_EN: [MessageHandler(Filters.text & ~Filters.command, translate_ru_en)],\n",
    "            SYNTHESIZE_EN: [MessageHandler(Filters.text & ~Filters.command, synthesize_en)],\n",
    "            SYNTHESIZE_RU: [MessageHandler(Filters.text & ~Filters.command, synthesize_ru)],\n",
    "            EXTRA: [MessageHandler(Filters.text & ~Filters.command, extra)],\n",
    "        },\n",
    "        fallbacks=[CommandHandler('menu', menu)],\n",
    "    ))\n",
    "    \n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until the user presses Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
