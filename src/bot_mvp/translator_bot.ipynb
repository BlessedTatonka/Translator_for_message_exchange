{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import regex\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import requests\n",
    "\n",
    "# !pip install python_telegram_bot\n",
    "\n",
    "import logging\n",
    "import soundfile as sf\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, ReplyKeyboardRemove, Update\n",
    "from telegram.ext import (\n",
    "    Updater,\n",
    "    CommandHandler,\n",
    "    MessageHandler,\n",
    "    Filters,\n",
    "    ConversationHandler,\n",
    "    CallbackContext,\n",
    "    CallbackQueryHandler\n",
    ")\n",
    "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import codecs\n",
    "import unidecode\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, Conversation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Grossmend/rudialogpt3_medium_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_param(text: str) -> str:\n",
    "    tokens_count = len(tokenizer.encode(text))\n",
    "    if tokens_count <= 15:\n",
    "        len_param = '1'\n",
    "    elif tokens_count <= 50:\n",
    "        len_param = '2'\n",
    "    elif tokens_count <= 256:\n",
    "        len_param = '3'\n",
    "    else:\n",
    "        len_param = '-'\n",
    "    return len_param\n",
    "\n",
    "\n",
    "def conversation(input_user, chat_history_ids=None):\n",
    "    \n",
    "    print(f\"===> User: {input_user}\")\n",
    "    \n",
    "    # encode the new user input, add parameters and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(f\"|0|{get_length_param(input_user)}|\" + input_user + tokenizer.eos_token +  \"|1|1|\", return_tensors=\"pt\")\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids\n",
    "    \n",
    "    # generated a response\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        num_return_sequences=1,\n",
    "        max_length=512,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "        temperature = 0.6,\n",
    "        mask_token_id=tokenizer.mask_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        unk_token_id=tokenizer.unk_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        device='cpu',\n",
    "    )\n",
    "    \n",
    "    # pretty print last ouput tokens from bot\n",
    "    decoded = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    print(f\"===> RuDialoGPT: {decoded}\")\n",
    "    \n",
    "    return decoded, chat_history_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> User: Привет\n",
      "===> RuDialoGPT: И тебе привет.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('И тебе привет.',\n",
       " tensor([[   96,    20,    96,    21,    96, 37954,     2,    96,    21,    96,\n",
       "             21,    96,   732,  1490,  6129,    18,     2]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation('Привет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/boris/F/token.txt') as token_file:\n",
    "    bot_token = token_file.readline().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/anaconda3/lib/python3.7/site-packages/telegram/ext/conversationhandler.py:288: UserWarning: If 'per_message=False', 'CallbackQueryHandler' will not be tracked for every message.\n",
      "  \"If 'per_message=False', 'CallbackQueryHandler' will not be \"\n",
      "2022-01-31 18:38:46,655 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2022-01-31 18:39:33,833 - __main__ - INFO - Bio of Boris: Привет\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> User: Привет\n",
      "===> RuDialoGPT: Здарова, сосед)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 18:40:13,713 - __main__ - INFO - Bio of Boris: Меня зовут Саша\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> User: Меня зовут Саша\n",
      "===> RuDialoGPT: Идиот.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 18:41:01,097 - __main__ - INFO - Bio of Boris: Анекдот\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> User: Анекдот\n",
      "===> RuDialoGPT: Ну и кто тут анекдот?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 18:41:20,259 - __main__ - INFO - Bio of Boris: Ты робот\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> User: Ты робот\n",
      "===> RuDialoGPT: А ты - нет\n"
     ]
    }
   ],
   "source": [
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "TRANSLATE_EN_RU, TRANSLATE_RU_EN, SYNTHESIZE_EN, SYNTHESIZE_RU, EXTRA = range(5)\n",
    "\n",
    "def normalize_str(txt) -> str:\n",
    "    # TODO: REPLACE WITH YOUR OWN NORMALIZATION LOGIC HERE!!!!   \n",
    "    valid_chars = (\" \", \"'\", \"!\", \".\", \"?\", \"&\",\n",
    "                   \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\",\n",
    "                   \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\",\n",
    "                   \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "                   \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\",\n",
    "                  )\n",
    "    new_txt = unidecode.unidecode(txt.lower().strip())\n",
    "    return new_txt\n",
    "#     res_arr = []\n",
    "#     for c in new_txt:\n",
    "#         if c in valid_chars:\n",
    "#             res_arr.append(c)\n",
    "#         else:\n",
    "#             res_arr.append(' ')\n",
    "#     res = ''.join(res_arr).strip()    \n",
    "#     return ' '.join(res.split())\n",
    "\n",
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    return menu(update, context)\n",
    "\n",
    "\n",
    "def menu(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Sends a message with three inline buttons attached.\"\"\"\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Translate en->ru\", callback_data='Translate en->ru'),\n",
    "            InlineKeyboardButton(\"Translate ru->en\", callback_data='Translate ru->en'),\n",
    "        ],\n",
    "        [\n",
    "            InlineKeyboardButton(\"Synthesize en\", callback_data='Synthesize en'),\n",
    "            InlineKeyboardButton(\"Synthesize ru\", callback_data='Synthesize ru')\n",
    "        ],\n",
    "        [InlineKeyboardButton(\"EXTRA\", callback_data='EXTRA')], ## REMOVE LATER\n",
    "        [InlineKeyboardButton(\"cancel\", callback_data='cancel')],\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "\n",
    "    update.message.reply_text('Please choose:', reply_markup=reply_markup)\n",
    "\n",
    "    return ConversationHandler.END\n",
    "\n",
    "def button(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Parses the CallbackQuery and updates the message text.\"\"\"\n",
    "    query = update.callback_query\n",
    "\n",
    "    # CallbackQueries need to be answered, even if no notification to the user is needed\n",
    "    # Some clients may have trouble otherwise. See https://core.telegram.org/bots/api#callbackquery\n",
    "    query.answer()\n",
    "\n",
    "    query.edit_message_text(text=f\"Selected option: {query.data}\")\n",
    "\n",
    "    if query.data == \"Translate en->ru\":\n",
    "        return TRANSLATE_EN_RU\n",
    "    elif query.data == \"Translate ru->en\":\n",
    "        return TRANSLATE_RU_EN\n",
    "    elif query.data == \"Synthesize en\":\n",
    "        return SYNTHESIZE_EN\n",
    "    elif query.data == \"Synthesize ru\":\n",
    "        return SYNTHESIZE_RU\n",
    "    elif query.data == \"cancel\":\n",
    "        return ConversationHandler.END\n",
    "    elif query.data == \"EXTRA\":\n",
    "        return EXTRA\n",
    "\n",
    "\n",
    "def help_command(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Displays info on how to use the bot.\"\"\"\n",
    "    update.message.reply_text(\"Use /start to test this bot.\")\n",
    "\n",
    "    \n",
    "def get_message(update: Update) -> str:\n",
    "    message = update.message.text\n",
    "    \n",
    "    message = message.replace('?', '&quest')\n",
    "    \n",
    "    return message\n",
    "    \n",
    "def translate_en_ru(update: Update, context: CallbackContext) -> None:\n",
    "    translate(update, context, 'en', 'ru')                \n",
    "    \n",
    "def translate_ru_en(update: Update, context: CallbackContext) -> None:\n",
    "    translate(update, context, 'ru', 'en')\n",
    "    \n",
    "def translate(update: Update, context: CallbackContext, src_lang, trg_lang) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = get_message(update)\n",
    "    request = requests.get(f'http://127.0.0.1:8000/translate/{message}?src_lang={src_lang}&trg_lang={trg_lang}')\n",
    "    \n",
    "    translation = request.json()['translation']\n",
    "    \n",
    "    update.message.reply_text(translation[0]) \n",
    "    \n",
    "def translate(text, src_lang, trg_lang) -> str:\n",
    "    request = requests.get(f'http://127.0.0.1:8000/translate/{text}?src_lang={src_lang}&trg_lang={trg_lang}')\n",
    "    translation = request.json()['translation']\n",
    "    return translation[0]\n",
    "    \n",
    "    \n",
    "def synthesize_en(update: Update, context: CallbackContext) -> None:\n",
    "    synthesize(update, context, 'en')\n",
    "    \n",
    "def synthesize_ru(update: Update, context: CallbackContext) -> None:\n",
    "    synthesize(update, context, 'ru')\n",
    "    \n",
    "def synthesize(update: Update, context: CallbackContext, src_lang) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = get_message(update)\n",
    "    message = normalize_str(message)\n",
    "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{message}?src_lang={src_lang}')\n",
    "    \n",
    "    audio = request.json()['audio']\n",
    "    \n",
    "    audio_name = 'audio/' + message[:12] + '.wav'\n",
    "    \n",
    "    sf.write(audio_name, audio, 22050)\n",
    "    \n",
    "    context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "\n",
    "def synthesize(text, src_lang):\n",
    "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{text}?src_lang={src_lang}')\n",
    "    \n",
    "    audio = request.json()['audio']\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=22050)\n",
    "    \n",
    "    return reduced_noise\n",
    "    \n",
    "# def extra(update: Update, context: CallbackContext) -> None:\n",
    "#     user = update.message.from_user\n",
    "#     logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "#     message = update.message.text\n",
    "#     print('Original message', message)\n",
    "#     message = translate(message.replace('?', '&quest'), 'ru', 'en')\n",
    "#     print('En translated', message)\n",
    "    \n",
    "#     conv = Conversation(message)\n",
    "#     conversational_pipeline(conv)\n",
    "#     response = conv.generated_responses[0]\n",
    "    \n",
    "#     message = translate(response.replace('?', '&quest'), 'en', 'ru')\n",
    "#     print('Ru translated', message)\n",
    "#     normalized = normalize_str(message)\n",
    "#     print(normalized)            \n",
    "                               \n",
    "#     if normalized == '':\n",
    "#         normalized = '.'\n",
    "    \n",
    "#     audio = synthesize(normalized, 'ru')\n",
    "#     audio_name = 'audio/' + response + '.wav'\n",
    "#     sf.write(audio_name, audio, 22050)\n",
    "    \n",
    "#     context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "    \n",
    "def extra(update: Update, context: CallbackContext) -> None:\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"Bio of %s: %s\", user.first_name, update.message.text)\n",
    "        \n",
    "    message = update.message.text\n",
    "        \n",
    "    response, chat_history_ids = conversation(message)\n",
    "    normalized_response = normalize_str(response.replace('?', '&quest'))\n",
    "    \n",
    "    if normalized_response == '':\n",
    "        normalized_response = '.'\n",
    "    \n",
    "    request = requests.get(f'http://127.0.0.1:8000/synthesize/{normalized_response}?src_lang=ru')\n",
    "    \n",
    "    \n",
    "    audio = request.json()['audio']\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=22050)\n",
    "    audio_name = 'audio/' + response + '.wav'\n",
    "    sf.write(audio_name, reduced_noise, 22050)\n",
    "    \n",
    "    context.bot.send_audio(chat_id=update.message.chat_id, audio=open(audio_name, 'rb'))\n",
    "    \n",
    "    \n",
    "def cancel(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Cancels and ends the conversation.\"\"\"\n",
    "    user = update.message.from_user\n",
    "    logger.info(\"User %s canceled the conversation.\", user.first_name)\n",
    "#     update.message.reply_text(\n",
    "#         'Пока.', reply_markup=ReplyKeyboardRemove()\n",
    "#     )\n",
    "\n",
    "    return menu(update, context)\n",
    "\n",
    "    \n",
    "def main() -> None:\n",
    "    \"\"\"Run the bot.\"\"\"\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    updater = Updater(bot_token)\n",
    "\n",
    "    updater.dispatcher.add_handler(CommandHandler('start', start))\n",
    "#     updater.dispatcher.add_handler(CommandHandler('menu', menu))\n",
    "#     updater.dispatcher.add_handler(CallbackQueryHandler(button))\n",
    "    updater.dispatcher.add_handler(CommandHandler('help', help_command))\n",
    "    updater.dispatcher.add_handler(ConversationHandler(\n",
    "        entry_points=[CallbackQueryHandler(button)],\n",
    "        states={\n",
    "            TRANSLATE_EN_RU: [MessageHandler(Filters.text & ~Filters.command, translate_en_ru)],\n",
    "            TRANSLATE_RU_EN: [MessageHandler(Filters.text & ~Filters.command, translate_ru_en)],\n",
    "            SYNTHESIZE_EN: [MessageHandler(Filters.text & ~Filters.command, synthesize_en)],\n",
    "            SYNTHESIZE_RU: [MessageHandler(Filters.text & ~Filters.command, synthesize_ru)],\n",
    "            EXTRA: [MessageHandler(Filters.text & ~Filters.command, extra)],\n",
    "        },\n",
    "        fallbacks=[CommandHandler('menu', menu)],\n",
    "    ))\n",
    "    \n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until the user presses Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
