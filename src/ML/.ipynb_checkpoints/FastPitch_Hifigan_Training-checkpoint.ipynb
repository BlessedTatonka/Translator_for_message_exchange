{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf13a13",
   "metadata": {
    "id": "ef75d1d5"
   },
   "source": [
    "## Training FastPitch\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d57d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ruslan = '../../datasets/RUSLAN/train_manifest.json'\n",
    "test_ruslan = '../../datasets/RUSLAN/test_manifest.json'\n",
    "train_mcv = 'train.json'\n",
    "test_mcv = 'test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4cc9c1",
   "metadata": {
    "id": "LggELooctXCT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-27 09:40:55 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2022-03-27 09:40:57 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from pathlib import Path\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "\n",
    "try:\n",
    "    from ruamel.yaml import YAML\n",
    "except ModuleNotFoundError:\n",
    "    from ruamel_yaml import YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd3af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.tts.models import FastPitchModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from nemo.collections.common.callbacks import LogEpochTimeCallback\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "import noisereduce as nr\n",
    "\n",
    "from nemo.collections.tts.torch.g2ps import EnglishG2p\n",
    "from nemo.collections.tts.torch.data import TTSDataset\n",
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "from nemo.collections.tts.torch.tts_tokenizers import EnglishPhonemesTokenizer, EnglishCharsTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30f8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6804cb",
   "metadata": {
    "id": "reY1LV4lwWoq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-12 23:25:31 optimizers:47] Apex was not found. Using the lamb optimizer will error out.\n",
      "[NeMo W 2022-02-12 23:25:31 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2022-02-12 23:25:32 nmse_clustering:54] Using eigen decomposition from scipy, upgrade torch to 1.9 or higher for faster clustering\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2022-02-12 23:25:32 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "      '\"sox\" backend is being deprecated. '\n",
      "    \n",
      "[NeMo W 2022-02-12 23:25:32 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali._AudioTextDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-02-12 23:25:32 fastpitch2_finetune:27] You are using an optimizer scheduler while finetuning. Are you sure this is intended?\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "[NeMo I 2022-02-12 23:25:32 exp_manager:220] Experiments will be logged at fastpitch_exp_manager/FastPitch/2022-02-12_23-25-07\n",
      "[NeMo I 2022-02-12 23:25:32 exp_manager:569] TensorboardLogger has been set up\n",
      "[NeMo W 2022-02-12 23:25:32 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:241: LightningDeprecationWarning: `ModelCheckpoint(every_n_val_epochs)` is deprecated in v1.4 and will be removed in v1.6. Please use `every_n_epochs` instead.\n",
      "      \"`ModelCheckpoint(every_n_val_epochs)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "    \n",
      "[NeMo E 2022-02-12 23:25:32 fastpitch:345] The train dataloader for FastPitchModel() has shuffle set to False!!!\n",
      "[NeMo E 2022-02-12 23:25:32 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.asr.data.vocabs.Phonemes object at 0x7fef0f2ae350>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo I 2022-02-12 23:25:35 collections:173] Dataset loaded with 17070 files totalling 25.82 hours\n",
      "[NeMo I 2022-02-12 23:25:35 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo E 2022-02-12 23:25:48 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.asr.data.vocabs.Phonemes object at 0x7feeefee4490>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo I 2022-02-12 23:25:50 collections:173] Dataset loaded with 8425 files totalling 13.69 hours\n",
      "[NeMo I 2022-02-12 23:25:50 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo E 2022-02-12 23:25:57 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.asr.data.vocabs.Phonemes object at 0x7feee7ae00d0>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo I 2022-02-12 23:25:58 features:262] PADDING: 1\n",
      "[NeMo I 2022-02-12 23:25:58 features:279] STFT using torch\n",
      "[NeMo W 2022-02-12 23:25:59 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_train.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 32\n",
      "      num_workers: 12\n",
      "    \n",
      "[NeMo W 2022-02-12 23:25:59 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_val.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 32\n",
      "      num_workers: 8\n",
      "    \n",
      "[NeMo E 2022-02-12 23:25:59 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.asr.data.vocabs.Phonemes object at 0x7feed02e3090>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo I 2022-02-12 23:26:00 features:262] PADDING: 1\n",
      "[NeMo I 2022-02-12 23:26:00 features:279] STFT using torch\n",
      "[NeMo I 2022-02-12 23:26:01 save_restore_connector:143] Model FastPitchModel was successfully restored from /media/boris/F/NeMo_own_research/tts/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-02-12 23:26:01 modelPT:882] Model checkpoint restored from nemo file with path : `./tts_en_fastpitch_align.nemo`\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\n"
     ]
    }
   ],
   "source": [
    "!HYDRA_FULL_ERROR=1 python fastpitch2_finetune.py \\\n",
    "    --config-name=fastpitch_align.yaml \\\n",
    "    train_dataset='train.json'\\\n",
    "    validation_datasets='test.json'\\\n",
    "    prior_folder=./Priors_qqq \\\n",
    "    model.train_ds.dataloader_params.batch_size=8 \\\n",
    "    model.validation_ds.dataloader_params.batch_size=1 \\\n",
    "    exp_manager.exp_dir=./fastpitch_exp_manager \\\n",
    "    model.optim.name=adam \\\n",
    "    +init_from_nemo_model=./tts_en_fastpitch_align.nemo\n",
    "\n",
    "#     model.optim.lr=1e-1 \\\n",
    "#     trainer.max_epochs=30 \\\n",
    "#     model.preprocessor.log_zero_guard_value=1e-2 \\\n",
    "\n",
    "#     +trainer.max_steps=1000 \\\n",
    "#     ~trainer.max_epochs \\\n",
    "#     +init_from_nemo_model=./tts_en_fastpitch_align.nemo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c26a72",
   "metadata": {
    "id": "886c91dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nemo.collections.tts.models import HifiGanModel\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "\n",
    "vocoder = HifiGanModel.from_pretrained(\"tts_hifigan\")\n",
    "vocoder.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876b21c7",
   "metadata": {
    "id": "0a4c986f"
   },
   "outputs": [],
   "source": [
    "def infer(spec_gen_model, vocoder_model, str_input, speaker = None):\n",
    "    \"\"\"\n",
    "    Synthesizes spectrogram and audio from a text string given a spectrogram synthesis and vocoder model.\n",
    "    \n",
    "    Arguments:\n",
    "    spec_gen_model -- Instance of FastPitch model\n",
    "    vocoder_model -- Instance of a vocoder model (HiFiGAN in our case)\n",
    "    str_input -- Text input for the synthesis\n",
    "    speaker -- Speaker number (in the case of a multi-speaker model -- in the mixing case)\n",
    "    \n",
    "    Returns:\n",
    "    spectrogram, waveform of the synthesized audio.\n",
    "    \"\"\"\n",
    "    parser_model = spec_gen_model\n",
    "    with torch.no_grad():\n",
    "        parsed = parser_model.parse(str_input)\n",
    "        if speaker is not None:\n",
    "            speaker = torch.tensor([speaker]).long().cuda()\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(tokens=parsed, speaker = speaker)\n",
    "        audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "        \n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to('cpu').numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to('cpu').numpy()\n",
    "    return spectrogram, audio\n",
    "\n",
    "def get_best_ckpt(experiment_base_dir, new_speaker_id, duration_mins, mixing_enabled, original_speaker_id):\n",
    "    \"\"\"\n",
    "    Gives the model checkpoint paths of an experiment  we ran. \n",
    "    \n",
    "    Arguments:\n",
    "    experiment_base_dir -- Base experiment directory (specified on top of this notebook as exp_base_dir)\n",
    "    new_speaker_id -- Speaker id of new HiFiTTS speaker we finetuned FastPitch on\n",
    "    duration_mins -- total minutes of the new speaker data\n",
    "    mixing_enabled -- True or False depending on whether we want to mix the original speaker data or not\n",
    "    original_speaker_id -- speaker id of the original HiFiTTS speaker\n",
    "    \n",
    "    Returns:\n",
    "    List of all checkpoint paths sorted by validation error, Last checkpoint path\n",
    "    \"\"\"\n",
    "    if not mixing_enabled:\n",
    "        exp_dir = \"{}/{}_to_{}_no_mixing_{}_mins\".format(experiment_base_dir, original_speaker_id, new_speaker_id, duration_mins)\n",
    "    else:\n",
    "        exp_dir = \"{}/{}_to_{}_mixing_{}_mins\".format(experiment_base_dir, original_speaker_id, new_speaker_id, duration_mins)\n",
    "    \n",
    "    ckpt_candidates = []\n",
    "    last_ckpt = None\n",
    "    for root, dirs, files in os.walk(exp_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ckpt\"):\n",
    "                val_error = float(file.split(\"v_loss=\")[1].split(\"-epoch\")[0])\n",
    "                if \"last\" in file:\n",
    "                    last_ckpt = os.path.join(root, file)\n",
    "                ckpt_candidates.append( (val_error, os.path.join(root, file)))\n",
    "    ckpt_candidates.sort()\n",
    "    \n",
    "    return ckpt_candidates, last_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1509c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ea3e295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-03-26 13:12:41 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fec4effde20>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo W 2022-03-26 13:12:44 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: ../../datasets/RUSLAN/train_manifest.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: ./priors_test\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 52.06\n",
      "      pitch_fmax: 490.0\n",
      "      pitch_avg: 266.1947700760956\n",
      "      pitch_std: 102.32474957051491\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 1\n",
      "      num_workers: 12\n",
      "    manifest_filepath: ../../datasets/RUSLAN/train_manifest.json\n",
      "    batch_size: 4\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-26 13:12:44 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: ../../datasets/RUSLAN/test_manifest.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: ./priors_test\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 52.06\n",
      "      pitch_fmax: 490.0\n",
      "      pitch_avg: 266.1947700760956\n",
      "      pitch_std: 102.32474957051491\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 1\n",
      "      num_workers: 12\n",
      "    manifest_filepath: ../../datasets/RUSLAN/test_manifest.json\n",
      "    batch_size: 1\n",
      "    num_workers: 4\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-26 13:12:44 features:259] PADDING: 1\n",
      "[NeMo I 2022-03-26 13:12:44 features:276] STFT using torch\n"
     ]
    }
   ],
   "source": [
    "duration_mins = 5\n",
    "mixing = False\n",
    "last_ckpt = '/media/boris/F/NeMo_own_research/tts/fastpitch_exp_manager/FastPitch/2022-01-31_02-26-12/checkpoints/FastPitch--v_loss=0.1481-epoch=20.ckpt'\n",
    "\n",
    "spec_model = FastPitchModel.load_from_checkpoint(last_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f5213d",
   "metadata": {
    "id": "8901f88b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_val = 5\n",
    "\n",
    "manifest_path = 'train.json'\n",
    "val_records = []\n",
    "with open(manifest_path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        val_records.append( json.loads(line) )\n",
    "        if len(val_records) >= num_val:\n",
    "            break\n",
    "            \n",
    "for val_record in val_records:\n",
    "    print (\"Real validation audio\")\n",
    "    ipd.display(ipd.Audio(val_record['audio_filepath'], rate=22050))\n",
    "    print (\"SYNTHESIZED\")\n",
    "    spec, audio = infer(spec_model, vocoder, val_record['text'], speaker=1)\n",
    "#     audio = nr.reduce_noise(y=audio, sr=22050)\n",
    "    ipd.display(ipd.Audio(audio, rate=22050))\n",
    "    %matplotlib inline\n",
    "    #if spec is not None:\n",
    "    imshow(spec, origin=\"lower\", aspect = \"auto\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5c89be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python hifigan_finetune.py \\\n",
    "    model.train_ds.dataloader_params.batch_size=4 \\\n",
    "    model.validation_ds.dataloader_params.batch_size=1 \\\n",
    "    train_dataset='hifigan_train_ft.json' \\\n",
    "    validation_datasets='hifigan_val_ft.json' \\\n",
    "    exp_manager.exp_dir=hifigan_ft \\\n",
    "   +init_from_nemo_model=./tts_hifigan.nemo \\\n",
    "#     +trainer.max_steps=10 \\\n",
    "#     ~trainer.max_epochs \\\n",
    "# init_from_ptl_ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
