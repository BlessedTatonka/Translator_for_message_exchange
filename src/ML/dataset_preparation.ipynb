{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-27 10:17:39 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# import fastwer\n",
    "\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "import librosa\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import codecs\n",
    "import unidecode\n",
    "# import pitch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logic according to dataloader\n",
    "\n",
    "def normalize_str(txt) -> str:\n",
    "    valid_chars = (\" \", \"'\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\")\n",
    "    \n",
    "    new_txt = unidecode.unidecode(txt.lower().strip())\n",
    "    \n",
    "    res_arr = []\n",
    "    for c in new_txt:\n",
    "        if c in valid_chars:\n",
    "            res_arr.append(c)\n",
    "        else:\n",
    "            res_arr.append(' ')\n",
    "    res = ''.join(res_arr).strip()    \n",
    "    return ' '.join(res.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../'\n",
    "datasets_dir = '../../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19980it [02:58, 111.65it/s]\n",
      "2220it [00:18, 122.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifests created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Building Manifest Files For RUSLAN --- #\n",
    "\n",
    "# Function to build a manifest\n",
    "def build_manifest(transcripts_path, manifest_path, wav_path, test_size=0.1, random_state=42):\n",
    "    with open(transcripts_path, 'r') as fin:\n",
    "        metadata = pd.read_csv(fin, sep='|', names=['file_name', 'transcript', 'normalized'])\n",
    "        metadata_train, metadata_test = train_test_split(metadata, test_size=test_size, random_state=random_state)\n",
    "        for m, m_path in [(metadata_train, 'train_ruslan.json'), (metadata_test, 'test_ruslan.json')]:\n",
    "            with open(manifest_path + m_path, 'w', encoding='utf8') as fout:\n",
    "                for row in tqdm(m.iterrows()):\n",
    "                    file_id = row[1]['file_name']  # e.g. \"cen4-fash-b\"\n",
    "                    audio_path = os.path.join(\n",
    "                        manifest_path, wav_path, file_id + '.wav')\n",
    "\n",
    "                    duration = librosa.core.get_duration(filename=audio_path)\n",
    "                    \n",
    "                    if duration > 12:\n",
    "                        continue\n",
    "                    \n",
    "                    transcript = row[1]['transcript']\n",
    "\n",
    "                    # Write the metadata to the manifest\n",
    "                    metadata = {\n",
    "                        \"audio_filepath\": audio_path,\n",
    "                        \"duration\": duration,\n",
    "                        \"text\": normalize_str(transcript)\n",
    "                    }\n",
    "                    json.dump(metadata, fout, ensure_ascii=False)\n",
    "                    fout.write('\\n')\n",
    "\n",
    "# Building Manifests\n",
    "print(\"******\")\n",
    "train_transcripts = datasets_dir + '/RUSLAN/metadata_RUSLAN_22200.csv'\n",
    "manifest = datasets_dir + '/RUSLAN/'\n",
    "build_manifest(train_transcripts, manifest, 'RUSLAN')\n",
    "print(\"Manifests created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Building Manifest Files For MCV --- #\n",
    "def tsv_to_manifest(tsv_files, manifest_file, prefix):\n",
    "  manifests = []\n",
    "  speakers = []\n",
    "  for tsv_file in tsv_files:\n",
    "    print('Processing: {0}'.format(tsv_file))\n",
    "    dt = pd.read_csv(tsv_file, sep='\\t', encoding='utf8')\n",
    "    for index, row in dt.iterrows():\n",
    "      try:\n",
    "        entry = {}\n",
    "        os.system(\"mkdir -p wavs/{0}\".format(prefix))\n",
    "        mp3_file = \"clips/\" + row['path'] # + \".mp3\"\n",
    "        wav_file = \"wavs/{0}/\".format(prefix) + row['path'] + \".wav\"\n",
    "        subprocess.check_output(\"sox {0} -c 1 -r 22050 {1}\".format(mp3_file, wav_file), shell=True)\n",
    "        duration = subprocess.check_output(\n",
    "          \"soxi -D {0}\".format(wav_file), shell=True)\n",
    "        entry['audio_filepath'] = wav_file\n",
    "        entry['duration'] = float(duration)\n",
    "        entry['text'] = normalize_str(row['sentence'])\n",
    "        entry['speaker'] = row['client_id'][:10]\n",
    "        speakers.append(row['client_id'])\n",
    "        manifests.append(entry)\n",
    "      except:\n",
    "        print(\"SOMETHING WENT WRONG - IGNORING ENTRY\")\n",
    "\n",
    "  with codecs.open(manifest_file, 'w', encoding='utf-8') as fout:\n",
    "    for m in manifests:\n",
    "      fout.write(json.dumps(m, ensure_ascii=False) + '\\n')\n",
    "  print(len(set(speakers)))\n",
    "  print('Done!')\n",
    "\n",
    "tsv_to_manifest(['train.tsv'], 'train.json', 'train')\n",
    "tsv_to_manifest(['test.tsv'], 'test.json', 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
