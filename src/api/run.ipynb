{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-26 02:30:23 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2022-03-26 02:30:24 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-03-26 02:30:25 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_en_ru_transformer6x6/5ecb5abae99986a5bcd7ed79417b8317/nmt_en_ru_transformer6x6.nemo.\n",
      "[NeMo I 2022-03-26 02:30:25 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_en_ru_transformer6x6/5ecb5abae99986a5bcd7ed79417b8317/nmt_en_ru_transformer6x6.nemo\n",
      "[NeMo I 2022-03-26 02:30:25 common:704] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-03-26 02:30:30 tokenizer_utils:171] Getting YouTokenToMeTokenizer with model: /tmp/tmp6y_z6jqz/tokenizer.all.32000.BPE.model with r2l: False.\n",
      "[NeMo I 2022-03-26 02:30:30 tokenizer_utils:171] Getting YouTokenToMeTokenizer with model: /tmp/tmp6y_z6jqz/tokenizer.all.32000.BPE.model with r2l: False.\n",
      "[NeMo W 2022-03-26 02:30:30 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_zh/processed/batches.tokens.cwmt_news.septokenizer.16000.pkl\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_zh/processed/batches.tokens.cwmt_news.septokenizer.16000.pkl\n",
      "    tokens_in_batch: 16000\n",
      "    clean: true\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    load_from_cached_dataset: true\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:30 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2013-en-ru.clean.tok.src\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2013-en-ru.clean.tok.ref\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:30 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2014-en-ru.clean.tok.src\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2014-en-ru.clean.tok.ref\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:30 nlp_overrides:221] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2022-03-26 02:30:30 modelPT:1242] World size can only be set by PyTorch Lightning Trainer.\n",
      "[NeMo I 2022-03-26 02:30:35 save_restore_connector:157] Model MTEncDecModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_en_ru_transformer6x6/5ecb5abae99986a5bcd7ed79417b8317/nmt_en_ru_transformer6x6.nemo.\n",
      "[NeMo I 2022-03-26 02:30:37 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_ru_en_transformer6x6/3db82426b17db1ae7cc7ae4ee3e3679b/nmt_ru_en_transformer6x6.nemo.\n",
      "[NeMo I 2022-03-26 02:30:37 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_ru_en_transformer6x6/3db82426b17db1ae7cc7ae4ee3e3679b/nmt_ru_en_transformer6x6.nemo\n",
      "[NeMo I 2022-03-26 02:30:37 common:704] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-03-26 02:30:42 tokenizer_utils:171] Getting YouTokenToMeTokenizer with model: /tmp/tmpgpu0qnvr/tokenizer.all.32000.BPE.model with r2l: False.\n",
      "[NeMo I 2022-03-26 02:30:42 tokenizer_utils:171] Getting YouTokenToMeTokenizer with model: /tmp/tmpgpu0qnvr/tokenizer.all.32000.BPE.model with r2l: False.\n",
      "[NeMo W 2022-03-26 02:30:42 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_zh/processed/batches.tokens.cmwt.septokenizer.16000.pkl\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_zh/processed/batches.tokens.cmwt.septokenizer.16000.pkl\n",
      "    tokens_in_batch: 16000\n",
      "    clean: true\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    load_from_cached_dataset: true\n",
      "    reverse_lang_direction: true\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:42 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2013-ru-en.clean.tok.src\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2013-ru-en.clean.tok.ref\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:42 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    src_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2014-ru-en.clean.tok.src\n",
      "    tgt_file_name: /home/sandeepsub/Datasets/wmt/wmt20_en_ru/parallel/newstest2014-ru-en.clean.tok.ref\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:42 nlp_overrides:221] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2022-03-26 02:30:42 modelPT:1242] World size can only be set by PyTorch Lightning Trainer.\n",
      "[NeMo I 2022-03-26 02:30:44 save_restore_connector:157] Model MTEncDecModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/nmt_ru_en_transformer6x6/3db82426b17db1ae7cc7ae4ee3e3679b/nmt_ru_en_transformer6x6.nemo.\n",
      "[NeMo I 2022-03-26 02:30:44 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-03-26 02:30:44 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo\n",
      "[NeMo I 2022-03-26 02:30:44 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-03-26 02:30:46 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7f5d40108e80>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo W 2022-03-26 02:30:47 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_train.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 32\n",
      "      num_workers: 12\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:47 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_val.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 32\n",
      "      num_workers: 8\n",
      "    \n",
      "[NeMo I 2022-03-26 02:30:47 features:259] PADDING: 1\n",
      "[NeMo I 2022-03-26 02:30:47 features:276] STFT using torch\n",
      "[NeMo I 2022-03-26 02:30:47 save_restore_connector:157] Model FastPitchModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-03-26 02:30:47 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo I 2022-03-26 02:30:47 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
      "[NeMo I 2022-03-26 02:30:47 common:704] Instantiating model from pre-trained checkpoint\n",
      "[NeMo W 2022-03-26 02:30:49 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
      "      min_duration: 0.75\n",
      "      n_segments: 8192\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:49 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
      "      min_duration: 3\n",
      "      n_segments: 66150\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 5\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:49 features:233] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n",
      "[NeMo I 2022-03-26 02:30:49 features:259] PADDING: 0\n",
      "[NeMo I 2022-03-26 02:30:49 features:276] STFT using torch\n",
      "[NeMo W 2022-03-26 02:30:49 features:233] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n",
      "[NeMo I 2022-03-26 02:30:49 features:259] PADDING: 0\n",
      "[NeMo I 2022-03-26 02:30:49 features:276] STFT using torch\n",
      "[NeMo I 2022-03-26 02:30:50 save_restore_connector:157] Model HifiGanModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo E 2022-03-26 02:30:50 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7f5cdc256520>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo W 2022-03-26 02:30:51 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: ../../datasets/RUSLAN/train_manifest.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: ./priors_test\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 1\n",
      "      num_workers: 12\n",
      "    manifest_filepath: ../../datasets/RUSLAN/train_manifest.json\n",
      "    batch_size: 1\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-26 02:30:51 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: ../../datasets/RUSLAN/test_manifest.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: ./priors_test\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 1\n",
      "      num_workers: 12\n",
      "    manifest_filepath: ../../datasets/RUSLAN/test_manifest.json\n",
      "    batch_size: 1\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo I 2022-03-26 02:30:51 features:259] PADDING: 1\n",
      "[NeMo I 2022-03-26 02:30:51 features:276] STFT using torch\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m174531\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:25565\u001b[0m (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-26 02:30:57 nemo_logging:349] /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages/nemo/collections/nlp/modules/common/transformer/transformer_generators.py:363: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "      mems_ids = indices_i.unsqueeze(2).unsqueeze(3).repeat(1, 1, p_len - 1, hidden_size) // self.beam_size\n",
      "    \n",
      "\u001b[32mINFO\u001b[0m:     192.168.3.2:47826 - \"\u001b[1mGET /translate/%D0%A1%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%BD%D1%8B%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B3%D1%83%20%D1%81%20%D1%8D%D1%82%D0%B8%D0%BC%20%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%82%D1%81%D1%8F?src_lang=ru&trg_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     192.168.3.2:47826 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     192.168.3.2:47828 - \"\u001b[1mGET /translate/%D0%A1%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%BD%D1%8B%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B3%D1%83%20%D1%81%20%D1%8D%D1%82%D0%B8%D0%BC%20%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%82%D1%81%D1%8F?src_lang=ru&trg_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     10.10.80.37:45650 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     10.10.80.37:45650 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     10.10.80.37:45652 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     10.10.80.37:45654 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:36172 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:36172 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     192.168.3.2:47830 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     192.168.3.2:47832 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     37.139.254.132:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /dummy_audio HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/Hi?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/%D0%BF%D1%83%D0%BA?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/qweqweqwe?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/qweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqwe?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/%D1%8F%20%D1%85%D0%BE%D1%87%D1%83%20%D0%BF%D0%B8%D1%86%D1%86%D1%83?src_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/%D0%BE%D1%81%D1%82%D0%B0%D0%BD%D1%8C%20%D1%84%D1%80%D0%B8%D0%BA%20%D0%B2%D0%BE%D0%BD%D1%8E%D1%87%D0%BA%D0%B0?src_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/%D0%A2%D0%AB%20%D0%A1%D0%9B%D0%90%D0%91%D0%9E%D0%A1%D0%A2%D0%AC%20qsdasd%20?src_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/%D0%B5%D0%B1%D0%B0%D0%BB%D0%BE%20%D1%81%D0%B2%D0%BE%D0%B5%20%D0%B7%D0%B0%D0%BA%D1%80%D0%BE%D0%B9?src_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/qweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqweqwe?src_lang=en&trg_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/%D0%A1%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%BD%D1%8B%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B3%D1%83%20%D1%81%20%D1%8D%D1%82%D0%B8%D0%BC%20%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%82%D1%81%D1%8F?src_lang=ru&trg_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /translate/%D0%A1%20%D0%B4%D1%80%D1%83%D0%B3%D0%BE%D0%B9%20%D1%81%D1%82%D0%BE%D1%80%D0%BE%D0%BD%D1%8B%20%D0%BD%D0%B5%20%D0%BC%D0%BE%D0%B3%D1%83%20%D1%81%20%D1%8D%D1%82%D0%B8%D0%BC%20%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%82%D1%8C%D1%81%D1%8F?src_lang=ru&trg_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/On%20the%20other%20hand%20I%20cannot%20agree%20with%20this?src_lang=ru HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/On%20the%20other%20hand%20I%20cannot%20agree%20with%20this?src_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     193.176.84.214:0 - \"\u001b[1mGET /synthesize/%D1%8F%20%D1%85%D0%BE%D1%87%D1%83%20%D0%BF%D0%B8%D1%86%D1%86%D1%83?src_lang=en HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m174531\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!uvicorn main:app --host 0.0.0.0 --port 25565 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt -p 25565 -s \"translator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting noisereduce\n",
      "  Using cached noisereduce-2.0.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: librosa in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (0.9.1)\n",
      "Requirement already satisfied: scipy in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (1.8.0)\n",
      "Requirement already satisfied: numpy in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (4.63.0)\n",
      "Requirement already satisfied: matplotlib in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (3.5.1)\n",
      "Requirement already satisfied: joblib in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from noisereduce) (1.1.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (0.55.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (1.0.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (1.6.0)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (5.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from librosa->noisereduce) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from numba>=0.45.1->librosa->noisereduce) (59.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from packaging>=20.0->librosa->noisereduce) (3.0.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.8)\n",
      "Requirement already satisfied: six>=1.3 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from resampy>=0.2.2->librosa->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa->noisereduce) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from matplotlib->noisereduce) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from matplotlib->noisereduce) (4.30.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from matplotlib->noisereduce) (1.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Installing collected packages: noisereduce\n",
      "Successfully installed noisereduce-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:38:58 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-03-15 18:38:58 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo\n",
      "[NeMo I 2022-03-15 18:38:58 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-03-15 18:38:59 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fe72212bd90>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "[NeMo W 2022-03-15 18:39:00 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_train.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 32\n",
      "      num_workers: 12\n",
      "    \n",
      "[NeMo W 2022-03-15 18:39:00 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_val.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 32\n",
      "      num_workers: 8\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:39:00 features:259] PADDING: 1\n",
      "[NeMo I 2022-03-15 18:39:00 features:276] STFT using torch\n",
      "[NeMo I 2022-03-15 18:39:01 save_restore_connector:157] Model FastPitchModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_en_fastpitch_align/b50e16c5d695b00855ae53d6ba4e4f7f/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2022-03-15 18:39:01 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo I 2022-03-15 18:39:01 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
      "[NeMo I 2022-03-15 18:39:01 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:39:02 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
      "      min_duration: 0.75\n",
      "      n_segments: 8192\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-15 18:39:02 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
      "      min_duration: 3\n",
      "      n_segments: 66150\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 5\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2022-03-15 18:39:02 features:233] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:39:02 features:259] PADDING: 0\n",
      "[NeMo I 2022-03-15 18:39:02 features:276] STFT using torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:39:02 features:233] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:39:02 features:259] PADDING: 0\n",
      "[NeMo I 2022-03-15 18:39:02 features:276] STFT using torch\n",
      "[NeMo I 2022-03-15 18:39:03 save_restore_connector:157] Model HifiGanModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.8.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:39:03 fastpitch:201] parse() is meant to be called in eval mode.\n",
      "[NeMo W 2022-03-15 18:39:03 fastpitch:264] generate_spectrogram() is meant to be called in eval mode.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from nemo.collections.tts.models import HifiGanModel\n",
    "\n",
    "spec_gen = FastPitchModel.from_pretrained('tts_en_fastpitch')\n",
    "vocoder = HifiGanModel.from_pretrained('tts_hifigan')\n",
    "\n",
    "# audio = nr.reduce_noise(y=audio, sr=22050)\n",
    "\n",
    "# sf.write(f'audio/{normalized_text}.wav', audio, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:39:12 fastpitch:201] parse() is meant to be called in eval mode.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mspec_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mпривет\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m spec_gen\u001b[38;5;241m.\u001b[39mgenerate_spectrogram(tokens\u001b[38;5;241m=\u001b[39mparsed)\n\u001b[1;32m      3\u001b[0m waveform \u001b[38;5;241m=\u001b[39m vocoder\u001b[38;5;241m.\u001b[39mconvert_spectrogram_to_audio(spec\u001b[38;5;241m=\u001b[39mspectrogram)\n",
      "File \u001b[0;32m/media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages/nemo/collections/tts/models/fastpitch.py:213\u001b[0m, in \u001b[0;36mFastPitchModel.parse\u001b[0;34m(self, str_input, normalize)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# Disable mixed g2p representation if necessary\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m eval_phon_mode:\n\u001b[0;32m--> 213\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# TODO(Oktai15): remove it in 1.8.0 version\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser(str_input)\n",
      "File \u001b[0;32m/media/boris/F/anaconda3/envs/nemo/lib/python3.9/site-packages/nemo/collections/common/data/vocabs.py:372\u001b[0m, in \u001b[0;36mPhonemes.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    369\u001b[0m         ps\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Remove trailing spaces\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m space:\n\u001b[1;32m    373\u001b[0m     ps\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_with_space:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "parsed = spec_gen.parse('привет')\n",
    "spectrogram = spec_gen.generate_spectrogram(tokens=parsed)\n",
    "waveform = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "\n",
    "audio = waveform[0].cpu().detach().numpy().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
